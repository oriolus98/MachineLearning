# Conclusiones
Con este trabajo hemos abordado los diferentes métodos de aprendizaje supervisado y no supervisado tratados en la asignatura de Machine Learning 1, enfocados al tratamiento de imágenes hiperespectrales.

En primer lugar, se han abordado diferentes métodos para reducir la dimensionalidad del conjunto de datos originales (análisis de componentes principales y selección de características relevantes en un clasificador). Este paso es muy importante, ya que actualmente se trabaja con conjuntos muy grandes de datos, y la selección de características necesarias permite reducir en gran medida los costes computacionales, económicos y temporales de cualquier proyecto. Por ejemplo, si se plantea monitorizar mediante imágenes hiperespectrales los campos de cultivo de un país como el nuestro, resultaría prohibitivo utilizar todas las bandas del espectro incluyendo aquellas que no aportan ninguna información.

A continuación, dada la naturaleza no etiquetada de la mayoría de los datasets de imágenes hiperespectrales, hemos utilizado diferentes algoritmos de aprendizaje no supervisado para clasificar los datos en diferentes grupos. El número óptimo de grupos encontrado es de 5 clusters (coeficiente Silouette), diferente de las 16 clases que sabemos tiene el problema. Esto demuestra las limitaciones de agrupar muestras sin conocer el número de clusters de antemano, cuando las características de varios grupos son similares. Los mejores resultados se han conseguido mediante los algoritmos k-means y Spectral Cluster, siendo preferible el primero dado su menor tiempo de ejecución.

Seguidamente hemos utilizado diferentes clasificadores supervisados ya que tenemos la etiqueta correspondiente a cada píxel. Hemos utilizado el algoritmo k-medoids para seleccionar únicamente 5000 muestras representativas del conjunto (con el mismo desbalanceo de clases) con tal de simular la situación típica en el análisis de imágenes de satélite, en las cuales las muestras etiquetadas son escasas. En los tres clasificadores utilizados (knn, árbol de decisión y SVM) hemos dividido el conjunto de datos reducido en un subconjunto de entrenamiento y otro de test. Hemos optimizado los hiperparámetros de cada clasificador mediante un gridsearch sobre el conjunto de entrenamiento (el cual utiliza el método de validación cruzada) y finalmente hemos validado el clasificador obtenido con el conjunto de test, obteniendo un error menor del 10 % en todos los casos. El clasificador con mejor rendimiento ha sido el SVM con un 94.4% (kappa), ligeramente por encima de los otros dos.

Finalmente, hemos recurrido a los métodos ensemble para intentar mejorar aún más el rendimiento de nuestro modelo. De esta forma, hemos probado un random Forest y un Adaboost con random forest como estimador base. En ambos casos, los resultados han sido muy similares a los ya obtenidos anteriormente (94.6 kappa score en ambos casos). Aún así, el tiempo de computación no es mucho más largo y se trata de métodos más robustos, por lo que sería recomendable recurrir a ellos para el análisis de otro tipo de imágenes como la que hemos tratado.

Además, hemos podido comprobar cualitativamente la validez de nuestros modelos: cuando se aplican sobre la imágen completa, el mapa obtenido es muy similar al GroundTruth. Al intentar determinar la causa del error mediante la matriz de confusión, vemos que en general aparecen muy pocos errores fruto del azar en la mayoría de clases. Sin embargo, todos los clasificadores arrojan sistemáticamente confusión significativa entre las clases 1 y 2, por lo que si quisiéramos mejorar el clasificador deberíamos profundizar en esto.
